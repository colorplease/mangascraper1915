# CI/CD Pipeline Documentation

This document explains the Continuous Integration and Continuous Deployment (CI/CD) setup for the Manga Scraper project.

## Overview

The CI/CD pipeline automatically runs tests, code quality checks, and security scans whenever code is pushed to the repository or a pull request is created.

## Pipeline Structure

### ğŸ§ª **Test Jobs**
- **Multiple OS Support**: Tests run on Ubuntu, Windows, and macOS
- **Python Version Matrix**: Tests against Python 3.9, 3.10, 3.11, and 3.12
- **Test Categories**:
  - Unit tests (individual component testing)
  - Integration tests (full workflow testing)
  - Functionality tests (core feature validation)
  - Parser tests (URL parsing and HTML extraction)

### ğŸ” **Code Quality Jobs**
- **Linting**: Code style and standards enforcement (flake8)
- **Formatting**: Code formatting consistency (black)
- **Import Sorting**: Import organization (isort)
- **Type Checking**: Static type analysis (mypy)

### ğŸ”’ **Security Jobs**
- **Dependency Scanning**: Check for known vulnerabilities (safety)
- **Code Security**: Static security analysis (bandit)
- **Report Generation**: Security scan artifacts

### ğŸ“š **Documentation Jobs**
- **Documentation Building**: Automated docs generation
- **Artifact Creation**: Documentation artifacts

## Triggers

The pipeline runs on:
- **Push to main/develop branches**
- **Pull requests to main/develop branches**  
- **Daily schedule** (2 AM UTC) to catch dependency issues

## Test Coverage

### Core Functionality Tests
âœ… **Chapter Scraping**
- URL parsing and normalization
- HTML parsing for chapter links
- Pagination handling
- Image extraction
- Metadata extraction

âœ… **Comment Processing**
- Comment extraction from HTML
- Text processing and cleaning
- Sentiment analysis and summarization
- File output operations

âœ… **Database Operations**
- CRUD operations (Create, Read, Update, Delete)
- Search and filtering
- Statistics generation
- Transaction handling

âœ… **Parser Functions**
- `extract_chapter_info()` - Extract episode numbers and titles from URLs
- `extract_webtoon_info()` - Extract series information from URLs
- `parse_chapter_links()` - Find chapter links in HTML
- `parse_manga_metadata()` - Extract manga metadata
- `parse_chapter_images()` - Extract image URLs

## Local Testing

### Run All Tests
```bash
# Run functionality tests (recommended)
python tests/test_runner.py --type functionality

# Run all tests
python tests/test_runner.py --type all

# Run specific test categories
python tests/test_runner.py --type unit
python tests/test_runner.py --type integration
```

### Run Parser Tests Specifically
```bash
# Run parser unit tests
python -m unittest tests.test_parsers -v

# Run specific parser test methods
python -m unittest tests.test_parsers.TestExtractChapterInfo.test_extract_chapter_info_valid_url -v
python -m unittest tests.test_parsers.TestExtractChapterInfo.test_extract_chapter_info_invalid_url -v
```

### Code Quality Checks
```bash
# Install linting tools
pip install flake8 black isort mypy

# Run linting
flake8 --max-line-length=100 scraper/ models/ utils/

# Check formatting
black --check scraper/ models/ utils/

# Check import sorting
isort --check-only --profile black scraper/ models/ utils/

# Type checking
mypy scraper/ models/ utils/ --ignore-missing-imports
```

### Security Scanning
```bash
# Install security tools
pip install safety bandit

# Check dependencies
safety check

# Security scan
bandit -r scraper/ models/ utils/
```

## Pipeline Benefits

### ğŸš€ **Automated Quality Assurance**
- Catches bugs before they reach production
- Ensures code style consistency
- Validates all core functionality
- Cross-platform compatibility testing

### ğŸ”„ **Continuous Integration**
- Every commit is tested
- Pull requests are validated
- Immediate feedback on code changes
- Prevents regression issues

### ğŸ“Š **Comprehensive Reporting**
- Test coverage metrics
- Security vulnerability reports
- Code quality scores
- Cross-platform compatibility

### ğŸ›¡ï¸ **Security First**
- Dependency vulnerability scanning
- Static code security analysis
- Automated security reporting
- Early threat detection

## Understanding Test Results

### âœ… **Green Pipeline** (All checks pass)
- All tests passed across all platforms
- Code quality standards met
- No security vulnerabilities found
- Ready for deployment/merge

### âŒ **Red Pipeline** (Some checks failed)
- Check individual job logs for details
- Fix failing tests or code quality issues
- Address security vulnerabilities
- Re-run pipeline after fixes

### âš ï¸ **Yellow Pipeline** (Warnings)
- Tests passed but with warnings
- Code quality issues (non-blocking)
- Review recommendations
- Consider addressing warnings

## Best Practices

### ğŸ“ **Before Committing**
1. Run tests locally: `python tests/test_runner.py --type functionality`
2. Check code formatting: `black scraper/ models/ utils/`
3. Verify no linting errors: `flake8 scraper/ models/ utils/`
4. Ensure all imports are sorted: `isort scraper/ models/ utils/`

### ğŸ”€ **Pull Request Guidelines**
1. Ensure all CI checks pass
2. Add tests for new functionality
3. Update documentation if needed
4. Address any code review feedback

### ğŸ› **Debugging Failed Tests**
1. Check the specific job that failed
2. Look at the detailed error logs
3. Reproduce the issue locally
4. Fix the issue and push changes
5. Verify the pipeline passes

## Maintenance

### ğŸ”„ **Regular Updates**
- Python version matrix updates
- Dependency version updates
- Security tool updates
- Pipeline optimization

### ğŸ“ˆ **Monitoring**
- Track test execution times
- Monitor pipeline success rates
- Review security scan results
- Update test coverage goals

This CI/CD setup ensures that your manga scraper maintains high quality, security, and reliability across all supported platforms and Python versions! 